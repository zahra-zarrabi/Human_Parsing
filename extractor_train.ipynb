{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "JMDy6mOs5ErU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd 'drive/MyDrive/Exercise_56/Self-Correction-Human-Parsing'"
      ],
      "metadata": {
        "id": "g1SxBolm5lue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cq-MDmWBUuFZ"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/PeikeLi/Self-Correction-Human-Parsing.git\n",
        "# %mkdir weights\n",
        "# %mkdir input\n",
        "# %mkdir output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir gdown"
      ],
      "metadata": {
        "id": "OpC4IzFeKQBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUN9t5u9Vfr5"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "gdown.download(\"https://drive.google.com/uc?id=1E5YwNKW2VOEayK9mWCS3Kpsxf-3z04ZE\", 'weights/weights.pth')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ninja"
      ],
      "metadata": {
        "id": "FHbi-xvD-wHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBfeE0-pV8sx"
      },
      "outputs": [],
      "source": [
        "!python simple_extractor.py --dataset 'pascal' --model-restore \"./log/checkpoint_10.pth.tar\" --input-dir \"./data/train_images/1006.png\" --output-dir './my'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import cv2\n",
        "input_img = os.listdir('/content/drive/MyDrive/Exercise_56/Self-Correction-Human-Parsing/output')\n",
        "for image in input_img:\n",
        "  img = cv2.imread(os.path.join('/content/drive/MyDrive/Exercise_56/Self-Correction-Human-Parsing/output', image))\n",
        "  img_binary = np.zeros((img.shape[0], img.shape[1]), dtype='uint8')\n",
        "  for x in range(img.shape[0]):\n",
        "    for y in range(img.shape[1]):\n",
        "      if img[x, y, :].any():\n",
        "        img_binary[x, y] = 1\n",
        "      else:\n",
        "        img_binary[x, y] = 0\n",
        "  cv2.imwrite(os.path.join('/content/drive/MyDrive/Exercise_56/Self-Correction-Human-Parsing/input/input_binary',image), img_binary*255)\n"
      ],
      "metadata": {
        "id": "-jz6Ghb-PdQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7GQ1WSrLe6Ij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19bbac76-6bca-4af0-883c-3a6e86240c0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1051\n",
            "1051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'http://sceneparsing.csail.mit.edu/model/pretrained_resnet/resnet101-imagenet.pth' -P 'pretrain_model'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MERreoq6_4XL",
        "outputId": "eb2ff31d-9fe1-4f7f-dd0b-2c76fb2bad88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-01 10:24:52--  http://sceneparsing.csail.mit.edu/model/pretrained_resnet/resnet101-imagenet.pth\n",
            "Resolving sceneparsing.csail.mit.edu (sceneparsing.csail.mit.edu)... 128.30.195.26\n",
            "Connecting to sceneparsing.csail.mit.edu (sceneparsing.csail.mit.edu)|128.30.195.26|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 179197864 (171M)\n",
            "Saving to: ‘pretrain_model/resnet101-imagenet.pth’\n",
            "\n",
            "resnet101-imagenet. 100%[===================>] 170.90M  37.7MB/s    in 4.7s    \n",
            "\n",
            "2022-03-01 10:24:57 (36.3 MB/s) - ‘pretrain_model/resnet101-imagenet.pth’ saved [179197864/179197864]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --data-dir ./data --num-classes 7 --epochs 15 --batch-size 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSBaa_ecs7MP",
        "outputId": "775c886b-2c0b-4e61-8d46-d923d77ba374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(arch='resnet101', batch_size=2, cycle_epochs=10, data_dir='./data', epochs=15, eval_epochs=10, gpu='0,1,2', ignore_label=255, imagenet_pretrain='./pretrain_model/resnet101-imagenet.pth', input_size='473,473', lambda_c=0.1, lambda_e=1, lambda_s=1, learning_rate=0.007, log_dir='./log', model_restore='./log/checkpoint.pth.tar', momentum=0.9, num_classes=7, random_mirror=False, random_scale=False, schp_restore='./log/schp_checkpoint.pth.tar', schp_start=100, start_epoch=0, weight_decay=0.0005)\n",
            "image mean: [0.406, 0.456, 0.485]\n",
            "image std: [0.225, 0.224, 0.229]\n",
            "input space:BGR\n",
            "BGR Transformation\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Total training samples: 1051\n",
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "iter = 0 of 2625 completed, lr = 7.000000000000001e-05, loss = 3.7641170024871826\n",
            "iter = 100 of 2625 completed, lr = 7.000000000000001e-05, loss = 2.351364850997925\n",
            "epoch = 0 of 15 completed using 438.8355559889999 s\n",
            "iter = 200 of 2625 completed, lr = 0.000763, loss = 1.3370832204818726\n",
            "iter = 300 of 2625 completed, lr = 0.000763, loss = 0.9894418120384216\n",
            "epoch = 1 of 15 completed using 431.24933519500007 s\n",
            "iter = 400 of 2625 completed, lr = 0.001456, loss = 0.8481666445732117\n",
            "iter = 500 of 2625 completed, lr = 0.001456, loss = 0.6505537033081055\n",
            "epoch = 2 of 15 completed using 428.8076364586666 s\n",
            "iter = 600 of 2625 completed, lr = 0.0021490000000000003, loss = 0.6136947274208069\n",
            "epoch = 3 of 15 completed using 427.62860907174996 s\n",
            "iter = 700 of 2625 completed, lr = 0.0028420000000000003, loss = 0.5651328563690186\n",
            "iter = 800 of 2625 completed, lr = 0.0028420000000000003, loss = 0.5594324469566345\n",
            "epoch = 4 of 15 completed using 426.93098244760006 s\n",
            "iter = 900 of 2625 completed, lr = 0.0035350000000000004, loss = 0.5860272645950317\n",
            "iter = 1000 of 2625 completed, lr = 0.0035350000000000004, loss = 0.4079538583755493\n",
            "epoch = 5 of 15 completed using 426.50372878183333 s\n",
            "iter = 1100 of 2625 completed, lr = 0.004228, loss = 0.5024316906929016\n",
            "iter = 1200 of 2625 completed, lr = 0.004228, loss = 0.5715060234069824\n",
            "epoch = 6 of 15 completed using 426.47090036257134 s\n",
            "iter = 1300 of 2625 completed, lr = 0.004921, loss = 0.45864710211753845\n",
            "epoch = 7 of 15 completed using 426.21082057449996 s\n",
            "iter = 1400 of 2625 completed, lr = 0.005614, loss = 0.5038094520568848\n",
            "iter = 1500 of 2625 completed, lr = 0.005614, loss = 0.5680876970291138\n",
            "epoch = 8 of 15 completed using 425.88990611888886 s\n",
            "iter = 1600 of 2625 completed, lr = 0.006307, loss = 0.6457276344299316\n",
            "iter = 1700 of 2625 completed, lr = 0.006307, loss = 0.39925745129585266\n",
            "epoch = 9 of 15 completed using 425.6807657537 s\n",
            "iter = 1800 of 2625 completed, lr = 0.007, loss = 0.4376893639564514\n",
            "iter = 1900 of 2625 completed, lr = 0.007, loss = 0.450865775346756\n",
            "epoch = 10 of 15 completed using 425.429439066 s\n",
            "iter = 2000 of 2625 completed, lr = 0.006997889215621167, loss = 0.36889272928237915\n",
            "epoch = 11 of 15 completed using 425.19900672883335 s\n",
            "iter = 2100 of 2625 completed, lr = 0.006991559434150291, loss = 0.49314576387405396\n",
            "iter = 2200 of 2625 completed, lr = 0.006991559434150291, loss = 0.4304582476615906\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 231, in <module>\n",
            "    main()\n",
            "  File \"train.py\", line 198, in main\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 307, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 156, in backward\n",
            "    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "extractor_train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}